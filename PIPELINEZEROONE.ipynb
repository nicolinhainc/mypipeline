{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIBWiklok4meDTZXZEsYNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolinhainc/mypipeline/blob/master/PIPELINEZEROONE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD3fnUQGiSaQ",
        "colab_type": "code",
        "outputId": "9c13be62-9428-47a4-c8f3-6f10c22c9bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pwd  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiBkzlnNifj7",
        "colab_type": "code",
        "outputId": "f3f2dd7c-8ca5-4632-cd66-e0b444fdcb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWKczacPifgd",
        "colab_type": "code",
        "outputId": "12037a15-6e0c-4550-e007-5ab763354c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1XdwGEqKXeKH1NRhZXxCZo5T8mncwYHCC' -O ./Bet-n-dcm2nii.zip\n",
        "!unzip -q ./Bet-n-dcm2nii.zip\n",
        "!rm -rf images"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-24 19:59:53--  https://drive.google.com/uc?export=download&id=1XdwGEqKXeKH1NRhZXxCZo5T8mncwYHCC\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.14.78, 2607:f8b0:4007:80b::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.14.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0k-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i4ne0ik8ms5n27pmln4cokgcup7ntbdt/1587758400000/07380574639032097336/*/1XdwGEqKXeKH1NRhZXxCZo5T8mncwYHCC?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-04-24 20:00:01--  https://doc-0k-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i4ne0ik8ms5n27pmln4cokgcup7ntbdt/1587758400000/07380574639032097336/*/1XdwGEqKXeKH1NRhZXxCZo5T8mncwYHCC?e=download\n",
            "Resolving doc-0k-60-docs.googleusercontent.com (doc-0k-60-docs.googleusercontent.com)... 172.217.11.161, 2607:f8b0:4007:804::2001\n",
            "Connecting to doc-0k-60-docs.googleusercontent.com (doc-0k-60-docs.googleusercontent.com)|172.217.11.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘./Bet-n-dcm2nii.zip’\n",
            "\n",
            "./Bet-n-dcm2nii.zip     [    <=>             ]  12.52M  10.6MB/s    in 1.2s    \n",
            "\n",
            "2020-04-24 20:00:03 (10.6 MB/s) - ‘./Bet-n-dcm2nii.zip’ saved [13126916]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwGvEZAIifeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload the zip file yourself "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3a3PV9JifY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q ./adnitest10.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M96A31sGT2jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf './adnitest10/AD/.DS_Store'\n",
        "!rm -rf './adnitest10/CN/.DS_Store'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqv8_CSbifVx",
        "colab_type": "code",
        "outputId": "d341c75d-f241-4bda-de27-0267479b542c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!wget --no-check-certificate 'https://www.dropbox.com/s/78omroebht50042/icbm_avg_152_t1_tal_lin.nii.zip?dl=1' -O ./icbm152t1.zip\n",
        "!unzip -q ./icbm152t1.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-24 20:00:22--  https://www.dropbox.com/s/78omroebht50042/icbm_avg_152_t1_tal_lin.nii.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/78omroebht50042/icbm_avg_152_t1_tal_lin.nii.zip [following]\n",
            "--2020-04-24 20:00:22--  https://www.dropbox.com/s/dl/78omroebht50042/icbm_avg_152_t1_tal_lin.nii.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1207a63716f57cf72ac7566111.dl.dropboxusercontent.com/cd/0/get/A2d5TG1yO2toy-LWeJa_D6DmAKBlMnj0Hfh1tFWvQUbQWUhzK8MCw8dWD76wkMofRw9rHpbzAiIjk-0cQizwFtPnKEyuWKauFFcQ0Kc1USayTGH5enygdersRtSvTbIetVI/file?dl=1# [following]\n",
            "--2020-04-24 20:00:23--  https://uc1207a63716f57cf72ac7566111.dl.dropboxusercontent.com/cd/0/get/A2d5TG1yO2toy-LWeJa_D6DmAKBlMnj0Hfh1tFWvQUbQWUhzK8MCw8dWD76wkMofRw9rHpbzAiIjk-0cQizwFtPnKEyuWKauFFcQ0Kc1USayTGH5enygdersRtSvTbIetVI/file?dl=1\n",
            "Resolving uc1207a63716f57cf72ac7566111.dl.dropboxusercontent.com (uc1207a63716f57cf72ac7566111.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc1207a63716f57cf72ac7566111.dl.dropboxusercontent.com (uc1207a63716f57cf72ac7566111.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14475752 (14M) [application/binary]\n",
            "Saving to: ‘./icbm152t1.zip’\n",
            "\n",
            "./icbm152t1.zip     100%[===================>]  13.80M  37.0MB/s    in 0.4s    \n",
            "\n",
            "2020-04-24 20:00:24 (37.0 MB/s) - ‘./icbm152t1.zip’ saved [14475752/14475752]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20qqIk8difTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/AD/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j38us7CGZJGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import shutil\n",
        "import os\n",
        "import fnmatch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzmthqc5ifNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['FSLOUTPUTTYPE'] = 'NIFTI_GZ'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2yiIYobTAby",
        "colab_type": "code",
        "outputId": "26275d44-b46e-4944-a6e9-e200055ab2f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii')\n",
        "    for ser in ['T1.nii']: \n",
        "      nativenii_file = os.path.join (subj_path, ser)\n",
        "      newniigz_file = os.path.join (subj_path, ser)\n",
        "      with open(nativenii_file, 'rb') as f_in:\n",
        "        with gzip.open(newniigz_file + '.gz', 'wb') as f_out:\n",
        "          shutil.copyfileobj(f_in, f_out)\n",
        "        \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/AD/Patient7\n",
            "Working on adnitest10/AD/Patient6\n",
            "Working on adnitest10/AD/Patient1\n",
            "Working on adnitest10/AD/Patient3\n",
            "Working on adnitest10/AD/Patient10\n",
            "Working on adnitest10/AD/Patient8\n",
            "Working on adnitest10/AD/Patient2\n",
            "Working on adnitest10/AD/Patient4\n",
            "Working on adnitest10/AD/Patient9\n",
            "Working on adnitest10/AD/Patient5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2yAtE3olH1y",
        "colab_type": "code",
        "outputId": "6518bd9e-3316-495f-ab5c-396dc0c3aab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii')\n",
        "    for ser in ['T1.nii']: \n",
        "        niinative_file = os.path.join (subj_path, ser)\n",
        "# removes old files\n",
        "        \n",
        "        cmd = os.remove(niinative_file)\n",
        "        \n",
        "        print (cmd)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/AD/Patient7\n",
            "None\n",
            "Working on adnitest10/AD/Patient6\n",
            "None\n",
            "Working on adnitest10/AD/Patient1\n",
            "None\n",
            "Working on adnitest10/AD/Patient3\n",
            "None\n",
            "Working on adnitest10/AD/Patient10\n",
            "None\n",
            "Working on adnitest10/AD/Patient8\n",
            "None\n",
            "Working on adnitest10/AD/Patient2\n",
            "None\n",
            "Working on adnitest10/AD/Patient4\n",
            "None\n",
            "Working on adnitest10/AD/Patient9\n",
            "None\n",
            "Working on adnitest10/AD/Patient5\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-nP6WQgqXXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/CN/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqZnZDH5qYVb",
        "colab_type": "code",
        "outputId": "dcec593d-a3e8-4ecf-9058-45f05a3a0cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii')\n",
        "    for ser in ['T1.nii']: \n",
        "      nativenii_file = os.path.join (subj_path, ser)\n",
        "      newniigz_file = os.path.join (subj_path, ser)\n",
        "      with open(nativenii_file, 'rb') as f_in:\n",
        "        with gzip.open(newniigz_file + '.gz', 'wb') as f_out:\n",
        "          shutil.copyfileobj(f_in, f_out)\n",
        "        "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/CN/Patient7\n",
            "Working on adnitest10/CN/Patient6\n",
            "Working on adnitest10/CN/Patient1\n",
            "Working on adnitest10/CN/Patient3\n",
            "Working on adnitest10/CN/Patient10\n",
            "Working on adnitest10/CN/Patient8\n",
            "Working on adnitest10/CN/Patient2\n",
            "Working on adnitest10/CN/Patient4\n",
            "Working on adnitest10/CN/Patient9\n",
            "Working on adnitest10/CN/Patient5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqsxAO0PqYH9",
        "colab_type": "code",
        "outputId": "188af980-bd3a-4fdf-b8ad-46d0a6b7e6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii')\n",
        "    for ser in ['T1.nii']: \n",
        "        niinative_file = os.path.join (subj_path, ser)\n",
        "# removes old files\n",
        "        \n",
        "        cmd = os.remove(niinative_file)\n",
        "        \n",
        "        print (cmd)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/CN/Patient7\n",
            "None\n",
            "Working on adnitest10/CN/Patient6\n",
            "None\n",
            "Working on adnitest10/CN/Patient1\n",
            "None\n",
            "Working on adnitest10/CN/Patient3\n",
            "None\n",
            "Working on adnitest10/CN/Patient10\n",
            "None\n",
            "Working on adnitest10/CN/Patient8\n",
            "None\n",
            "Working on adnitest10/CN/Patient2\n",
            "None\n",
            "Working on adnitest10/CN/Patient4\n",
            "None\n",
            "Working on adnitest10/CN/Patient9\n",
            "None\n",
            "Working on adnitest10/CN/Patient5\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWsiOlB3qfvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/AD/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVXVKzU4ifK0",
        "colab_type": "code",
        "outputId": "3a850ef0-ffd7-4134-d96a-d7db620c0881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii.gz')\n",
        "    for ser in ['T1']: #not sure why I had to add the star here but this was the only way it worked\n",
        "        nii_file = os.path.join (subj_path, ser)\n",
        "# First, perform N4 bias correction. Not required, but may improve results. Also must track new names\n",
        "        new_file = os.path.join (subj_path, 'N4-' + ser)\n",
        "        cmd = \"./N4BiasFieldCorrection -i %s.nii.gz -o %s.nii.gz\" % (nii_file, new_file)\n",
        "        os.system(cmd)\n",
        "        print (cmd)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/AD/Patient7\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient7/T1.nii.gz -o adnitest10/AD/Patient7/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient6\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient6/T1.nii.gz -o adnitest10/AD/Patient6/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient1\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient1/T1.nii.gz -o adnitest10/AD/Patient1/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient3\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient3/T1.nii.gz -o adnitest10/AD/Patient3/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient10\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient10/T1.nii.gz -o adnitest10/AD/Patient10/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient8\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient8/T1.nii.gz -o adnitest10/AD/Patient8/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient2\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient2/T1.nii.gz -o adnitest10/AD/Patient2/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient4\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient4/T1.nii.gz -o adnitest10/AD/Patient4/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient9\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient9/T1.nii.gz -o adnitest10/AD/Patient9/N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient5\n",
            "./N4BiasFieldCorrection -i adnitest10/AD/Patient5/T1.nii.gz -o adnitest10/AD/Patient5/N4-T1.nii.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMf-kqTEx5B_",
        "colab_type": "code",
        "outputId": "50aacce0-12de-4ba1-8000-d0bab72daf38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii.gz')\n",
        "    for ser in ['T1.nii.gz']: #not sure why I had to add the star here but this was the only way it worked\n",
        "        nii_file = os.path.join (subj_path, ser)\n",
        "# removes old files\n",
        "        \n",
        "        cmd = os.remove(nii_file)\n",
        "        \n",
        "        print (cmd)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/AD/Patient7\n",
            "None\n",
            "Working on adnitest10/AD/Patient6\n",
            "None\n",
            "Working on adnitest10/AD/Patient1\n",
            "None\n",
            "Working on adnitest10/AD/Patient3\n",
            "None\n",
            "Working on adnitest10/AD/Patient10\n",
            "None\n",
            "Working on adnitest10/AD/Patient8\n",
            "None\n",
            "Working on adnitest10/AD/Patient2\n",
            "None\n",
            "Working on adnitest10/AD/Patient4\n",
            "None\n",
            "Working on adnitest10/AD/Patient9\n",
            "None\n",
            "Working on adnitest10/AD/Patient5\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTvuq8eBqmvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/CN/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdPHMOYqqmmt",
        "colab_type": "code",
        "outputId": "02d5e483-82c1-4bb0-a627-fcad2d720c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii.gz')\n",
        "    for ser in ['T1']: #not sure why I had to add the star here but this was the only way it worked\n",
        "        nii_file = os.path.join (subj_path, ser)\n",
        "# First, perform N4 bias correction. Not required, but may improve results. Also must track new names\n",
        "        new_file = os.path.join (subj_path, 'N4-' + ser)\n",
        "        cmd = \"./N4BiasFieldCorrection -i %s.nii.gz -o %s.nii.gz\" % (nii_file, new_file)\n",
        "        os.system(cmd)\n",
        "        print (cmd)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/CN/Patient7\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient7/T1.nii.gz -o adnitest10/CN/Patient7/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient6\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient6/T1.nii.gz -o adnitest10/CN/Patient6/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient1\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient1/T1.nii.gz -o adnitest10/CN/Patient1/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient3\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient3/T1.nii.gz -o adnitest10/CN/Patient3/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient10\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient10/T1.nii.gz -o adnitest10/CN/Patient10/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient8\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient8/T1.nii.gz -o adnitest10/CN/Patient8/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient2\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient2/T1.nii.gz -o adnitest10/CN/Patient2/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient4\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient4/T1.nii.gz -o adnitest10/CN/Patient4/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient9\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient9/T1.nii.gz -o adnitest10/CN/Patient9/N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient5\n",
            "./N4BiasFieldCorrection -i adnitest10/CN/Patient5/T1.nii.gz -o adnitest10/CN/Patient5/N4-T1.nii.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtoBFYnwqmdk",
        "colab_type": "code",
        "outputId": "4a833763-1f56-49a6-8fe3-7917251d23df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii.gz')\n",
        "    for ser in ['T1.nii.gz']: #not sure why I had to add the star here but this was the only way it worked\n",
        "        nii_file = os.path.join (subj_path, ser)\n",
        "# removes old files\n",
        "        \n",
        "        cmd = os.remove(nii_file)\n",
        "        \n",
        "        print (cmd)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/CN/Patient7\n",
            "None\n",
            "Working on adnitest10/CN/Patient6\n",
            "None\n",
            "Working on adnitest10/CN/Patient1\n",
            "None\n",
            "Working on adnitest10/CN/Patient3\n",
            "None\n",
            "Working on adnitest10/CN/Patient10\n",
            "None\n",
            "Working on adnitest10/CN/Patient8\n",
            "None\n",
            "Working on adnitest10/CN/Patient2\n",
            "None\n",
            "Working on adnitest10/CN/Patient4\n",
            "None\n",
            "Working on adnitest10/CN/Patient9\n",
            "None\n",
            "Working on adnitest10/CN/Patient5\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxlviDkNqukH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/AD/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifEYCCSdifFL",
        "colab_type": "code",
        "outputId": "688c84f7-45e4-4f27-991b-b546faf1a79f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Next, Register the images to the avg 152 t1 image from MNI\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), 'N4-*')\n",
        "    for ser in ['T1']:   \n",
        "        MNI_file = './icbm_avg_152_t1_tal_lin.nii'\n",
        "        T1_file =  os.path.join (subj_path, 'N4-T1*.nii.gz')\n",
        "        new_file = os.path.join (subj_path, 'Reg-N4-T1.nii.gz')\n",
        "        cmd = \"./flirt -in %s -ref %s  -out %s\" % (T1_file, MNI_file, new_file)\n",
        "        os.system(cmd)\n",
        "        print (cmd)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/AD/Patient7\n",
            "./flirt -in adnitest10/AD/Patient7/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient7/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient6\n",
            "./flirt -in adnitest10/AD/Patient6/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient6/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient1\n",
            "./flirt -in adnitest10/AD/Patient1/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient1/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient3\n",
            "./flirt -in adnitest10/AD/Patient3/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient3/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient10\n",
            "./flirt -in adnitest10/AD/Patient10/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient10/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient8\n",
            "./flirt -in adnitest10/AD/Patient8/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient8/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient2\n",
            "./flirt -in adnitest10/AD/Patient2/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient2/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient4\n",
            "./flirt -in adnitest10/AD/Patient4/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient4/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient9\n",
            "./flirt -in adnitest10/AD/Patient9/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient9/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/AD/Patient5\n",
            "./flirt -in adnitest10/AD/Patient5/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/AD/Patient5/Reg-N4-T1.nii.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-YAFnk3qJEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/CN/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM7Ao_rSqI_u",
        "colab_type": "code",
        "outputId": "53aa0b78-7fca-4563-9275-5c4324acd996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Next, Register the images to the avg 152 t1 image from MNI\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), 'N4-*')\n",
        "    for ser in ['T1']:   \n",
        "        MNI_file = './icbm_avg_152_t1_tal_lin.nii'\n",
        "        T1_file =  os.path.join (subj_path, 'N4-T1*.nii.gz')\n",
        "        new_file = os.path.join (subj_path, 'Reg-N4-T1.nii.gz')\n",
        "        cmd = \"./flirt -in %s -ref %s  -out %s\" % (T1_file, MNI_file, new_file)\n",
        "        os.system(cmd)\n",
        "        print (cmd)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on adnitest10/CN/Patient7\n",
            "./flirt -in adnitest10/CN/Patient7/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient7/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient6\n",
            "./flirt -in adnitest10/CN/Patient6/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient6/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient1\n",
            "./flirt -in adnitest10/CN/Patient1/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient1/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient3\n",
            "./flirt -in adnitest10/CN/Patient3/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient3/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient10\n",
            "./flirt -in adnitest10/CN/Patient10/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient10/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient8\n",
            "./flirt -in adnitest10/CN/Patient8/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient8/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient2\n",
            "./flirt -in adnitest10/CN/Patient2/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient2/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient4\n",
            "./flirt -in adnitest10/CN/Patient4/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient4/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient9\n",
            "./flirt -in adnitest10/CN/Patient9/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient9/Reg-N4-T1.nii.gz\n",
            "Working on adnitest10/CN/Patient5\n",
            "./flirt -in adnitest10/CN/Patient5/N4-T1*.nii.gz -ref ./icbm_avg_152_t1_tal_lin.nii  -out adnitest10/CN/Patient5/Reg-N4-T1.nii.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeHtpkFWifAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#manually create the valc1 and valc2 folders to make sure it works\n",
        "#below ref https://stackoverflow.com/questions/46717742/split-data-directory-into-training-and-test-directory-with-sub-directory-structu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfVEtsxt9dvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q ./adnitest10prepng.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwsehPxfuoT3",
        "colab_type": "code",
        "outputId": "e86d67b1-a5b2-4e2d-c532-da8954efe4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "   import os\n",
        "   import shutil\n",
        "   import numpy as np\n",
        "   base_dir = '/content/adnitest10'\n",
        "\n",
        "   !mkdir /content/adnitest10/ADval\n",
        "   !mkdir /content/adnitest10/CNval"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/adnitest10/ADval’: No such file or directory\n",
            "mkdir: cannot create directory ‘/content/adnitest10/CNval’: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUk9fqHGORYS",
        "colab_type": "code",
        "outputId": "2d22054d-3ff5-4d32-fa26-22d02768b165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sourceN = base_dir + \"/AD\"\n",
        "destN = base_dir + \"/ADval\"\n",
        "sourceP = base_dir + \"/CN\"\n",
        "destP = base_dir + \"/CNval\"\n",
        "\n",
        "filesN = os.listdir(sourceN)\n",
        "filesP = os.listdir(sourceP)       \n",
        "\n",
        "for f in filesN:\n",
        "  if np.random.rand(1) < 0.3: #is this a 70 30 split? what does it mean exactly?\n",
        "    shutil.move(sourceN + '/'+ f, destN + '/'+ f)\n",
        "\n",
        "for i in filesP:\n",
        "  if np.random.rand(1) < 0.3:\n",
        "    shutil.move(sourceP + '/'+ i, destP + '/'+ i)\n",
        "\n",
        "print(len(os.listdir(sourceN)))\n",
        "print(len(os.listdir(sourceP)))\n",
        "print(len(os.listdir(destN)))\n",
        "print(len(os.listdir(destP)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTF40yU7rz-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./LGG/valc2/.ipynb_checkpoints\n",
        "!rm -rf ./LGG/valc1/.ipynb_checkpoints\n",
        "\n",
        "!rm -rf './adnitest10/ADval/.ipynb_checkpoints'\n",
        "!rm -rf './adnitest10/CNval/.ipynb_checkpoints'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC1Uh6W9ie31",
        "colab_type": "code",
        "outputId": "1007f593-2f0c-4d0d-ae30-6bb311e15d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "#make a huge list of thousands of patients here\n",
        "import pandas as pd\n",
        "\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1z2GmRDDVMbcb1x26jlA9X0M4WAv4-kvA' -O ./TumorSlices.csv\n",
        "df = pd.read_csv ('./TumorSlices.csv')\n",
        "print (df) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-24 21:54:25--  https://drive.google.com/uc?export=download&id=1z2GmRDDVMbcb1x26jlA9X0M4WAv4-kvA\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.4.174, 2607:f8b0:4007:802::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.4.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/3ltmc48lti34kruahivmrnq1cc1ls2qv/1587765225000/07380574639032097336/*/1z2GmRDDVMbcb1x26jlA9X0M4WAv4-kvA?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-04-24 21:54:25--  https://doc-10-60-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/3ltmc48lti34kruahivmrnq1cc1ls2qv/1587765225000/07380574639032097336/*/1z2GmRDDVMbcb1x26jlA9X0M4WAv4-kvA?e=download\n",
            "Resolving doc-10-60-docs.googleusercontent.com (doc-10-60-docs.googleusercontent.com)... 172.217.11.161, 2607:f8b0:4007:804::2001\n",
            "Connecting to doc-10-60-docs.googleusercontent.com (doc-10-60-docs.googleusercontent.com)|172.217.11.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25558 (25K) [text/csv]\n",
            "Saving to: ‘./TumorSlices.csv’\n",
            "\n",
            "\r./TumorSlices.csv     0%[                    ]       0  --.-KB/s               \r./TumorSlices.csv   100%[===================>]  24.96K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-04-24 21:54:26 (1.25 MB/s) - ‘./TumorSlices.csv’ saved [25558/25558]\n",
            "\n",
            "          Subject  StartSlice  EndSlice\n",
            "0        Patient1           0       300\n",
            "1        Patient2           0       300\n",
            "2        Patient3           0       300\n",
            "3        Patient4           0       300\n",
            "4        Patient5           0       300\n",
            "...           ...         ...       ...\n",
            "1397  Patient1398           0       300\n",
            "1398  Patient1399           0       300\n",
            "1399  Patient1400           0       300\n",
            "1400  Patient1401           0       300\n",
            "1401  Patient1402           0       300\n",
            "\n",
            "[1402 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCzjZCcnie07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from __future__ import absolute_import\n",
        "# Cell #5\n",
        "# create new versions of the T1, GAD, and T2 images that range from 0 to 255, and where the 0 intensity value maps to the 5th percentile value \n",
        "# and 255 maps to the 95th percentile value.\n",
        "import imageio\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "MIN_MR = 20\n",
        "\n",
        "def normalise_zero_one(image):\n",
        "    dims = np.shape(image)\n",
        "    image_1d = image.reshape(1, image.size)\n",
        "    above = np.where(image_1d>MIN_MR, image_1d, image_1d)\n",
        "    if above.size < image_1d.size/2:\n",
        "        above = image_1d # avoid bad MIN_MR thresholds\n",
        "    sorted_im = np.sort(above, axis = None)\n",
        "    \n",
        "    start = int(sorted_im.size / 20)  # 20 = 5%\n",
        "    end = int(sorted_im.size * 19 / 20) # 95%\n",
        "    start_val = sorted_im[start]\n",
        "    end_val = sorted_im[end]\n",
        "    \n",
        "    image = np.maximum(image, start_val) # map values below the start_val to start_val\n",
        "    image = np.minimum(image, end_val)   # map values above the end_val to end_val\n",
        "    image = image - start_val # subtract the starting intensity\n",
        "\n",
        " #   print (\"rescaling range \" + str(newmin) + \" to \" + str(histo[1][index]))\n",
        "    minimum = np.min(image)\n",
        "    maximum = np.max(image)\n",
        "\n",
        "    ret = ((image - minimum) / (maximum - minimum))    \n",
        "    return ret    \n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nifti_to_img(red_file, green_file, blue_file, not_dir, yes_dir, startSlice, endSlice, subject):\n",
        "### red_ green_ and blue_files are the nifit files that will be combined to go into the PNG\n",
        "### not_dir is the direcotry where PNGs are stored if they are not in the (inclusive)\n",
        "### range set by startSlice/endSlice\n",
        "### yes_dir is where they are stored when they ARE in the range\n",
        "### subject is the ID so that we can track where images came from\n",
        "\n",
        "    try:\n",
        "        nifti = nib.load(red_file)\n",
        "        nif_header = nifti.header\n",
        "        red_image = nifti.get_fdata()\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "    try:\n",
        "        if os.path.isfile(green_file):\n",
        "            nifti = nib.load(green_file)\n",
        "            nif_header = nifti.header\n",
        "            green_image = nifti.get_fdata()\n",
        "        else:\n",
        "            pass\n",
        "    except:  # if can't load, then use red image\n",
        "        green_image = red_image\n",
        "    \n",
        "    try:\n",
        "        if os.path.isfile(blue_file):\n",
        "            nifti = nib.load(blue_file)\n",
        "\n",
        "            nif_header = nifti.header\n",
        "            blue_image = nifti.get_fdata()\n",
        "        else:\n",
        "            pass\n",
        "    except:  # if can't load, then use red image\n",
        "        blue_image = red_image\n",
        "        \n",
        "# now scale the intensity for each image        \n",
        "    red_image = normalise_zero_one(red_image)\n",
        "    green_image = normalise_zero_one(green_image)\n",
        "    blue_image = normalise_zero_one(blue_image)\n",
        "# then convert to 8 bits\n",
        "    red_image = red_image.astype(np.uint8)     \n",
        "    green_image = green_image.astype(np.uint8)     \n",
        "    blue_image = blue_image.astype(np.uint8)   \n",
        "    \n",
        "# get the number of slices\n",
        "    dims = np.shape(red_image)\n",
        "    zd = dims[2]\n",
        "\n",
        "    for z in range(0, zd):\n",
        "        outname = subject + \"-{0:04d}\".format(z) + '.png'\n",
        "        if z >= startSlice and z <= endSlice:  # this is enhancing\n",
        "            out_dir = yes_dir\n",
        "        else:\n",
        "            out_dir = not_dir\n",
        "        outname = os.path.join(out_dir, outname)\n",
        "        if not os.path.exists(out_dir):\n",
        "            os.makedirs(out_dir)\n",
        "        combined = np.dstack((red_image[:,:,z],green_image[:,:,z],\n",
        "                              blue_image[:,:,z]))\n",
        "## . images come in rotated\n",
        "        combined = np.rot90(combined, k=1)\n",
        "#        print ('Name: ' + outname)\n",
        "        imageio.imwrite(outname, combined)\n",
        "    return zd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETZHZsRFqNlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/AD/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iQuQDuwieyE",
        "colab_type": "code",
        "outputId": "8d80fa4d-6752-4c71-da55-ff4f644ef1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Cell #6\n",
        "# take the GAD nii, scale it to 0-255 and store that into the red channel\n",
        "# same for T1 (green) and T2 (blue)\n",
        "# PNG files are stored in enh / nonenh folders based on the csv file\n",
        "\n",
        "# store the png files into enhancing or nonenhancing folders after making sure they are cleared\n",
        "\n",
        "!rm -rf classified\n",
        "\n",
        "!mkdir classified\n",
        "\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    red_f = os.path.join(subj_path, 'Reg-N4-T1.nii.gz')\n",
        "    startSlice = df.loc[df.Subject == subj, 'StartSlice'].values[0]\n",
        "    endSlice = df.loc[df.Subject == subj, 'EndSlice'].values[0]\n",
        "    print (\"Making PNG file for \" + subj + \" start: \" + str(startSlice) + \" end: \" + str(endSlice))\n",
        "    count = nifti_to_img(red_f, red_f, red_f, NIFTI_PATH, NIFTI_PATH, startSlice, endSlice, subj)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making PNG file for Patient1 start: 0 end: 300\n",
            "Making PNG file for Patient3 start: 0 end: 300\n",
            "Making PNG file for Patient4 start: 0 end: 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiE_I9o-388G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree(subj_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac5yrvqjyTkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/CN/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwAEMqYkyTfD",
        "colab_type": "code",
        "outputId": "cbabfe01-5bf9-4973-a326-6ff83e85ff9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Cell #6\n",
        "# take the GAD nii, scale it to 0-255 and store that into the red channel\n",
        "# same for T1 (green) and T2 (blue)\n",
        "# PNG files are stored in enh / nonenh folders based on the csv file\n",
        "\n",
        "# store the png files into enhancing or nonenhancing folders after making sure they are cleared\n",
        "\n",
        "!rm -rf classified\n",
        "\n",
        "!mkdir classified\n",
        "\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    red_f = os.path.join(subj_path, 'Reg-N4-T1.nii.gz')\n",
        "    startSlice = df.loc[df.Subject == subj, 'StartSlice'].values[0]\n",
        "    endSlice = df.loc[df.Subject == subj, 'EndSlice'].values[0]\n",
        "    print (\"Making PNG file for \" + subj + \" start: \" + str(startSlice) + \" end: \" + str(endSlice))\n",
        "    count = nifti_to_img(red_f, red_f, red_f, NIFTI_PATH, NIFTI_PATH, startSlice, endSlice, subj)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making PNG file for Patient7 start: 0 end: 300\n",
            "Making PNG file for Patient1 start: 0 end: 300\n",
            "Making PNG file for Patient10 start: 0 end: 300\n",
            "Making PNG file for Patient4 start: 0 end: 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFK8niq637qC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree(subj_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndSUrz6iyTR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/ADval/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1fqSp70yTNa",
        "colab_type": "code",
        "outputId": "e8b466fd-3a2d-44d8-8c91-5d6b4bffd9ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Cell #6\n",
        "# take the GAD nii, scale it to 0-255 and store that into the red channel\n",
        "# same for T1 (green) and T2 (blue)\n",
        "# PNG files are stored in enh / nonenh folders based on the csv file\n",
        "\n",
        "# store the png files into enhancing or nonenhancing folders after making sure they are cleared\n",
        "\n",
        "!rm -rf classified\n",
        "\n",
        "!mkdir classified\n",
        "\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    red_f = os.path.join(subj_path, 'Reg-N4-T1.nii.gz')\n",
        "    startSlice = df.loc[df.Subject == subj, 'StartSlice'].values[0]\n",
        "    endSlice = df.loc[df.Subject == subj, 'EndSlice'].values[0]\n",
        "    print (\"Making PNG file for \" + subj + \" start: \" + str(startSlice) + \" end: \" + str(endSlice))\n",
        "    count = nifti_to_img(red_f, red_f, red_f, NIFTI_PATH, NIFTI_PATH, startSlice, endSlice, subj)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making PNG file for Patient7 start: 0 end: 300\n",
            "Making PNG file for Patient6 start: 0 end: 300\n",
            "Making PNG file for Patient10 start: 0 end: 300\n",
            "Making PNG file for Patient8 start: 0 end: 300\n",
            "Making PNG file for Patient2 start: 0 end: 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmjXByUN4Axk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree(subj_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOzD_LUDyTId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NIFTI_PATH = 'adnitest10/CNval/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RcnCfNpyS9O",
        "colab_type": "code",
        "outputId": "b9bd9105-d213-4c13-e7de-d52893af1d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "# Cell #6\n",
        "# take the GAD nii, scale it to 0-255 and store that into the red channel\n",
        "# same for T1 (green) and T2 (blue)\n",
        "# PNG files are stored in enh / nonenh folders based on the csv file\n",
        "\n",
        "# store the png files into enhancing or nonenhancing folders after making sure they are cleared\n",
        "\n",
        "!rm -rf classified\n",
        "\n",
        "!mkdir classified\n",
        "\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    red_f = os.path.join(subj_path, 'Reg-N4-T1.nii.gz')\n",
        "    startSlice = df.loc[df.Subject == subj, 'StartSlice'].values[0]\n",
        "    endSlice = df.loc[df.Subject == subj, 'EndSlice'].values[0]\n",
        "    print (\"Making PNG file for \" + subj + \" start: \" + str(startSlice) + \" end: \" + str(endSlice))\n",
        "    count = nifti_to_img(red_f, red_f, red_f, NIFTI_PATH, NIFTI_PATH, startSlice, endSlice, subj)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making PNG file for Patient6 start: 0 end: 300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-b3cbebccf993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mendSlice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubject\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msubj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EndSlice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Making PNG file for \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" start: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartSlice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" end: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendSlice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnifti_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mred_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mred_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mred_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNIFTI_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNIFTI_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartSlice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendSlice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-201fb785acd8>\u001b[0m in \u001b[0;36mnifti_to_img\u001b[0;34m(red_file, green_file, blue_file, not_dir, yes_dir, startSlice, endSlice, subject)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m#        print ('Name: ' + outname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mzd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimwrite\u001b[0;34m(uri, im, format, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m# Return a result if there is any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mappend_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0;31m# Call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mset_meta_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36m_append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_as_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbitdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mPillowFormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36m_append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"bits\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Make it a P image, so bits arg is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugin_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0msave_pillow_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"eXIf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m     \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du6VI9bi1nVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree(subj_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaUarkM-OfOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r ./adnitest10.zip ./adnitest10\n",
        "#then download it."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjxhxrhdqnRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#below code is from https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e\n",
        "#and https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a\n",
        "#get the githubs for the refs in the paper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPuqXkncieuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell #7\n",
        "# now we are ready to load data and train classifier\n",
        "# while we did this in separate cells before, we will do it all in one\n",
        "# this should look familiar.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "!pip install tensornets\n",
        "import tensornets as nets\n",
        "import tensorflow_hub as hub\n",
        "import keras\n",
        "import tensorflow.keras \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "from tensorflow.keras.applications.nasnet import NASNetLarge, NASNetMobile, preprocess_input\n",
        "directory = \"./content\"\n",
        "\n",
        "base_model=tensorflow.keras.applications.nasnet.NASNetLarge(input_shape=(331, 331, 3), include_top=False, weights='imagenet', input_tensor=None, pooling=None) #imports the nasnet large model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(2,activation='softmax')(x) #final layer with softmax activation, for 2 classes\n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds) # to load saved model with weights use model= tensorflow.keras.models.load_model('myLGGtestmodel.h5')\n",
        "#specify the inputs\n",
        "#specify the outputs\n",
        "#now a model has been created based on our architecture\n",
        "\n",
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "# or if we want to set the first 20 layers of the network to be non-trainable\n",
        "for layer in model.layers[:1039]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[1039:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "train_datagen=ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0, fill_mode='nearest', horizontal_flip=False, data_format='channels_last', validation_split=0.0, dtype='float32') #included in our dependencies\n",
        "# add the directory below very important ##########################\n",
        "\n",
        "train=train_datagen.flow_from_directory('./train',\n",
        "                                                 target_size=(331,331),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "val_datagen=ImageDataGenerator()\n",
        "\n",
        "val=val_datagen.flow_from_directory('./validate',\n",
        "                                                 target_size=(331,331),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=False)\n",
        "\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=train.n//train.batch_size\n",
        "step_size_val=val.n//val.batch_size\n",
        "#model.fit_generator(generator=train_generator,\n",
        "#                   steps_per_epoch=step_size_train,\n",
        "#                   epochs=3)\n",
        "\n",
        "history = model.fit(train, steps_per_epoch=step_size_train, epochs=3,\n",
        "                              validation_data=val, validation_steps=step_size_val, \n",
        "                              verbose=1)       \n",
        "\n",
        "\n",
        "    \n",
        "# next cell to save model including newly trained weights\n",
        "# model.save('myLGGtestmodel.h5') # rename it how you like, it will show up in your directory. I have explained above using a hastag how and where to load the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FAaux6jEYzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#above tips for the graph function: list range has to be 1 to #epochs+1\n",
        "#np.arrange has to be 0, #epochs +1 and no clue what the last number is."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegemgM0cquI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,4))\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 4, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 4, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o-zvwsrJPgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this cell is to evaluate loss and accuracy on an external test set\n",
        "\n",
        "model.evaluate(val, verbose=1, sample_weight=None, steps=step_size_val, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZFRaCuYkTfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this cell is to predict smaller numbers of images and so... it returns an array which I havent figured out yet...\n",
        "\n",
        "yhat = model.predict(val, verbose=1, steps=step_size_val, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmEgUsRlGnD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions on your choice of numbers in dataset, just change the range https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
        "\n",
        "\t\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_blobs\n",
        "# create the inputs and outputs\n",
        "X, y = make_blobs(n_samples=5000, centers=2, n_features=2, random_state=2)\n",
        "# define model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make predictions on the entire training dataset\n",
        "yhat = model.predict(X)\n",
        "# connect predictions with outputs\n",
        "for i in range(5000):\n",
        "  print (X[i], yhat[i])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubpYDLuJXQhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load_model_sample.py TRY THIS FOR A SINGLE IMAGE https://stackoverflow.com/questions/43469281/how-to-predict-input-image-using-trained-model-in-keras\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "def load_image(img_path, show=False):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # load model\n",
        "    model = load_model(\"model_aug.h5\")\n",
        "\n",
        "    # image path\n",
        "    img_path = '/media/data/dogscats/test1/3867.jpg'    # dog\n",
        "    #img_path = '/media/data/dogscats/test1/19.jpg'      # cat\n",
        "\n",
        "    # load a single image\n",
        "    new_image = load_image(img_path)\n",
        "\n",
        "    # check prediction\n",
        "    pred = model.predict(new_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHTq1g_n64x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TRY this also for a single image https://stackoverflow.com/questions/43469281/how-to-predict-input-image-using-trained-model-in-keras\n",
        "# load_model_sample.py\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "def load_image(img_path, show=False):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # load model\n",
        "    model = load_model(\"model_aug.h5\")\n",
        "\n",
        "    # image path\n",
        "    img_path = '/media/data/dogscats/test1/3867.jpg'    # dog\n",
        "    #img_path = '/media/data/dogscats/test1/19.jpg'      # cat\n",
        "\n",
        "    # load a single image\n",
        "    new_image = load_image(img_path)\n",
        "\n",
        "    # check prediction\n",
        "    pred = model.predict(new_image)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}